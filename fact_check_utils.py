"""
Fact-Check å·¥å…· - æ™ºèƒ½æ‘˜è¦å’ŒéªŒè¯
ç»“åˆçŸ¥è¯†åº“æ£€ç´¢å’Œå¯é€‰çš„ç½‘ç»œæœç´¢ï¼Œç”Ÿæˆæ€»ç»“æ€§æ–‡æœ¬
"""

import os
from langchain_community.llms import Tongyi
from dotenv import load_dotenv

load_dotenv()

def get_friendly_filename(source_file):
    """
    Convert technical source file names to user-friendly names
    """
    filename_mapping = {
        # Your Excel mappings
        '41_S_1-43.pdf': 'Simons et al 2013 - Diablotin Pterodroma hasitata Biography of the Black-capped Petrel',
        '2024FloodZinos1stBritain.pdf': 'Flood 2024 - Zino\'s Petrel off Scilly new to Britain',
        '3906_pterodroma_madeira.pdf': 'BirdLife International 2021 - Pterodroma madeira Zinos Petrel',
        'Conservation_of_Zinos_petrel_Pterodroma.pdf': 'Zino et al 2001 - Conservation of Zinos petrel Pterodroma madeira in Madeira',
        'conservation-of-zinos-petrel-pterodroma-madeira-in-the-archipelago-of-madeira.pdf': 'Zino et al 2001 - Conservation of Zinos petrel Pterodroma madeira in Madeira',
        'Madeira_Zinos_Petrel_2010_0.pdf': 'BirdLife International 2010 - Race against the clock to save Zinos Petrel',
        'Madeira-2021.pdf': 'Flood 2021 - ORIOLE BIRDING TOUR TO MADEIRA ENDEMICS AND SEABIRDS 5-9 JULY 2021',
        'madeira-2024-text.pdf': 'Koppenol 2024 - MADEIRA TOUR REPORT 2024',
        'Madeira2004_NB.pdf': 'Brinkley 2004 - Zinos Petrel at sea off Madeira 27 April 2004',
        'pterodromaRefs_v1.15.pdf': 'Hobbs 2017 - Pterodroma Reference List - Comprehensive bibliography of gadfly petrels',
        'Shirihai_Jamaica_AtSea_Nov09.pdf': 'Shirihai et al 2010 - Jamaica Petrel Pterodroma caribbaea Pelagic expedition report',
        'srep23447.pdf': 'Ramos et al 2016 - Global spatial ecology of three closely related gadfly petrels',
        'The_separation_of_Pterodroma_madeira_Zin.pdf': 'Zino et al 2008 - The separation of Pterodroma madeira from Pterodroma feae',
        'v36n6p586.pdf': 'Patteson & Brinkley 2004 - A Petrel Primer - The Gadflies of North Carolina',
        'v40n6p28.pdf': 'Hess 2008 - Feas or Zinos Petrel',
        'Zino_s_Petrel_Pterodroma_madeira_off_Nor.pdf': 'Patteson et al 2013 - Zinos Petrel Pterodroma madeira off North Carolina - First for North America',
        'zinos-petrel-1995.pdf': 'Zino et al 1995 - Action Plan for Zinos Petrel Pterodroma madeira',
        'zlae123.pdf': 'Rando et al 2024 - Pterodroma zinorum Biography of an extinct Azorean petrel',
        
        # Default fallback
        'unknown': 'Unknown Document'
    }
    
    base_name = os.path.basename(source_file) if source_file else 'unknown'
    return filename_mapping.get(base_name, base_name.replace('_', ' ').replace('-', ' ').title())


def summarize_fact_check(question, retrieved_docs, ai_answer, language="English"):
    """
    å¯¹ Fact-Check å†…å®¹è¿›è¡Œæ™ºèƒ½æ‘˜è¦
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        ai_answer: AI çš„å›ç­”
        language: è¯­è¨€ï¼ˆEnglish/Portugueseï¼‰
    
    Returns:
        str: æ€»ç»“æ€§æ–‡æœ¬
    """
    # æå–æ–‡æ¡£å†…å®¹
    doc_contents = []
    sources = []
    
    for i, doc in enumerate(retrieved_docs[:3], 1):  # æœ€å¤šä½¿ç”¨3ä¸ªæ–‡æ¡£
        content = doc.page_content[:500]  # æ¯ä¸ªæ–‡æ¡£æœ€å¤š500å­—ç¬¦
        source = doc.metadata.get('source_file', 'Unknown')
        page = doc.metadata.get('page', 'N/A')

        friendly_name = get_friendly_filename(source)
        
        doc_contents.append(f"[Source {i}: {friendly_name}, Page {page}]\n{content}")
        sources.append(f"{friendly_name} (p.{page})")
    
    combined_docs = "\n\n".join(doc_contents)
    
    # æ„å»ºæ‘˜è¦ Prompt
    if language == "Portuguese":
        prompt = f"""
        Tu Ã©s um verificador de factos cientÃ­fico. Com base nos documentos fornecidos, cria um resumo claro e conciso.

        **Pergunta do utilizador:** {question}

        **Resposta da IA:** {ai_answer}

        **Documentos de referÃªncia:**
        {combined_docs}

        **Tua tarefa:**
        1. Resume os pontos-chave dos documentos que apoiam a resposta
        2. Menciona dados especÃ­ficos (nÃºmeros, locais, datas) se disponÃ­veis
        3. MantÃ©m o resumo abaixo de 100 palavras
        4. Usa linguagem simples e clara
        5. Se os documentos nÃ£o apoiam a resposta, indica isso

        **Resumo factual:**
        """
    else:
        prompt = f"""
        You are a scientific fact-checker. Based on the provided documents, create a clear and concise summary.

        **User's Question:** {question}

        **AI's Answer:** {ai_answer}

        **Reference Documents:**
        {combined_docs}

        **Your Task:**
        1. Summarize key points from the documents that support the answer
        2. Mention specific data (numbers, locations, dates) if available
        3. Keep the summary under 100 words
        4. Use simple, clear language
        5. If documents don't support the answer, indicate that

        **Factual Summary:**
        """
    
    # ä½¿ç”¨ Qwen LLM ç”Ÿæˆæ‘˜è¦
    try:
        api_key = os.getenv("DASHSCOPE_API_KEY")
        llm = Tongyi(
            model_name=os.getenv("QWEN_MODEL_NAME", "qwen-turbo"),
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œç¡®ä¿äº‹å®æ€§
            dashscope_api_key=api_key
        )
        
        summary = llm.invoke(prompt)
        
        # æ·»åŠ æ¥æºå¼•ç”¨
        if language == "Portuguese":
            source_text = f"\n\nğŸ“š **Fontes:** {', '.join(sources)}"
        else:
            source_text = f"\n\nğŸ“š **Sources:** {', '.join(sources)}"
        
        return summary.strip() + source_text
    
    except Exception as e:
        print(f"[Fact-Check] æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        # é™çº§ï¼šè¿”å›ç®€åŒ–çš„æ–‡æ¡£å†…å®¹
        source = retrieved_docs[0].metadata.get('source_file', 'Unknown')
        page = retrieved_docs[0].metadata.get('page', 'N/A')
        friendly_name = get_friendly_filename(source)
        
        if language == "Portuguese":
            return f"ğŸ“„ InformaÃ§Ã£o extraÃ­da dos documentos:\n\n{retrieved_docs[0].page_content[:200]}...\n\nğŸ“š Fonte: {friendly_name} (p.{page})"
        else:
            return f"ğŸ“„ Information from documents:\n\n{retrieved_docs[0].page_content[:200]}...\n\nğŸ“š Source: {friendly_name} (p.{page})"


def optimize_search_query(question, retrieved_docs):
    """
    åŸºäºç”¨æˆ·é—®é¢˜å’Œ RAG æ£€ç´¢å†…å®¹ä¼˜åŒ–æœç´¢æŸ¥è¯¢
    
    Args:
        question: ç”¨æˆ·åŸå§‹é—®é¢˜
        retrieved_docs: RAG æ£€ç´¢åˆ°çš„æ–‡æ¡£
    
    Returns:
        str: ä¼˜åŒ–åçš„æœç´¢æŸ¥è¯¢
    """
    # ä» RAG æ–‡æ¡£ä¸­æå–å…³é”®æ¦‚å¿µ
    rag_keywords = set()
    for doc in retrieved_docs[:2]:  # åªçœ‹å‰2ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
        content = doc.page_content.lower()
        # æå–å…³é”®ç”Ÿç‰©å­¦/ä¿æŠ¤ç›¸å…³è¯æ±‡
        bio_keywords = ['seabird', 'petrel', 'bird', 'endemic', 'madeira', 'conservation', 
                        'endangered', 'breeding', 'nesting', 'habitat', 'species', 'population']
        for keyword in bio_keywords:
            if keyword in content:
                rag_keywords.add(keyword)
    
    # æ„å»ºç²¾å‡†æœç´¢æŸ¥è¯¢
    base_query = "Zino's Petrel"
    
    # æ·»åŠ ç›¸å…³ä¸Šä¸‹æ–‡å…³é”®è¯
    if 'conservation' in rag_keywords or 'endangered' in rag_keywords:
        base_query += " conservation status"
    elif 'breeding' in rag_keywords or 'nesting' in rag_keywords:
        base_query += " breeding habitat"
    elif 'madeira' in rag_keywords:
        base_query += " Madeira island"
    else:
        base_query += " seabird biology"
    
    # æ·»åŠ è‹±æ–‡å…³é”®è¯ç¡®ä¿æœç´¢è´¨é‡
    base_query += " bird species"
    
    return base_query


def filter_search_results(results, question):
    """
    æ™ºèƒ½è¿‡æ»¤æœç´¢ç»“æœï¼Œæ’é™¤æ— å…³å†…å®¹
    
    Args:
        results: åŸå§‹æœç´¢ç»“æœåˆ—è¡¨
        question: ç”¨æˆ·é—®é¢˜
    
    Returns:
        list: è¿‡æ»¤åçš„ç›¸å…³ç»“æœ
    """
    filtered = []
    
    # ç›¸å…³å…³é”®è¯ï¼ˆç”Ÿç‰©å­¦/ä¿æŠ¤ç›¸å…³ï¼‰
    relevant_keywords = [
        'petrel', 'bird', 'seabird', 'species', 'madeira', 'conservation', 
        'endangered', 'breeding', 'habitat', 'ornithology', 'wildlife',
        'pterodroma', 'freira', 'endemic', 'biodiversity'
    ]
    
    # æ— å…³å…³é”®è¯ï¼ˆæŠ€æœ¯/ç¼–ç¨‹ç›¸å…³ï¼‰
    irrelevant_keywords = [
        'framework', 'programming', 'code', 'software', 'api', 'rust',
        'ç¼–ç¨‹', 'æ¡†æ¶', 'å¼€å‘', 'ä»£ç ', 'github', 'npm', 'cargo'
    ]
    
    for result in results:
        title = result.get('title', '').lower()
        body = result.get('body', '').lower()
        combined = title + ' ' + body
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ— å…³å…³é”®è¯
        has_irrelevant = any(keyword in combined for keyword in irrelevant_keywords)
        if has_irrelevant:
            print(f"[Fact-Check] è¿‡æ»¤æ— å…³ç»“æœ: {result.get('title', 'Unknown')[:50]}...")
            continue
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
        has_relevant = any(keyword in combined for keyword in relevant_keywords)
        if has_relevant:
            filtered.append(result)
    
    return filtered


def web_search_supplement(question, retrieved_docs=None, language="English"):
    """
    æ™ºèƒ½ç½‘ç»œæœç´¢è¡¥å……ä¿¡æ¯
    æ”¯æŒ DuckDuckGoï¼ˆå…è´¹ï¼‰å’Œ Tavilyï¼ˆéœ€ API Keyï¼‰
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        retrieved_docs: RAG æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼ˆç”¨äºä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼‰
        language: è¯­è¨€
    
    Returns:
        str: ç½‘ç»œæœç´¢ç»“æœæ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢
    use_web_search = os.getenv("USE_WEB_SEARCH", "false").lower() == "true"
    
    if not use_web_search:
        return None
    
    # ä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼ˆåŸºäº RAG ä¸Šä¸‹æ–‡ï¼‰
    if retrieved_docs and len(retrieved_docs) > 0:
        optimized_query = optimize_search_query(question, retrieved_docs)
        print(f"[Fact-Check] ä¼˜åŒ–æœç´¢æŸ¥è¯¢: {optimized_query}")
    else:
        optimized_query = f"Zino's Petrel {question} bird species"
    
    # è·å–æœç´¢æä¾›å•†ï¼ˆé»˜è®¤ duckduckgoï¼‰
    provider = os.getenv("WEB_SEARCH_PROVIDER", "duckduckgo").lower()
    
    # æ–¹æ¡ˆ 1: DuckDuckGoï¼ˆå®Œå…¨å…è´¹ï¼Œæ— éœ€ API Keyï¼‰
    results = []  # åˆå§‹åŒ– results å˜é‡
    
    if provider == "duckduckgo":
        try:
            from ddgs import DDGS
            
            # ä½¿ç”¨æ–°ç‰ˆ APIï¼ˆæ— éœ€ context managerï¼‰
            ddgs = DDGS()
            # æ–°ç‰ˆ APIï¼šå‚æ•°åæ˜¯ query è€Œä¸æ˜¯ keywords
            raw_results = list(ddgs.text(
                query=optimized_query,
                max_results=5  # å¤šè·å–ä¸€äº›ç»“æœï¼Œåç»­è¿‡æ»¤
            ))
            
            # æ™ºèƒ½è¿‡æ»¤ç»“æœ
            results = filter_search_results(raw_results, question)
            print(f"[Fact-Check] åŸå§‹ç»“æœ: {len(raw_results)} â†’ è¿‡æ»¤å: {len(results)}")
            
            if results:
                if language == "Portuguese":
                    summary = "ğŸŒ **InformaÃ§Ã£o da Internet:**\n\n"
                else:
                    summary = "ğŸŒ **Internet Information:**\n\n"
                
                # åªæ˜¾ç¤ºå‰2ä¸ªæœ€ç›¸å…³çš„ç»“æœ
                for i, result in enumerate(results[:2], 1):
                    title = result.get('title', 'Unknown')
                    body = result.get('body', '')[:150]
                    url = result.get('href', '')
                    
                    summary += f"{i}. **{title}**\n   {body}...\n   ğŸ”— {url}\n\n"
                
                return summary.strip()
        
        except ImportError:
            print("[Fact-Check] DDGS æœªå®‰è£…ï¼Œè¿è¡Œ: pip install ddgs")
        except Exception as e:
            print(f"[Fact-Check] DuckDuckGo æœç´¢å¤±è´¥: {str(e)}")
            print(f"[Fact-Check] å°è¯•é™çº§åˆ° Tavily...")
    
    # æ–¹æ¡ˆ 2: Tavilyï¼ˆéœ€è¦ API Keyï¼Œ1000 æ¬¡/æœˆå…è´¹ï¼‰
    # å¦‚æœ DuckDuckGo å¤±è´¥æˆ–æä¾›å•†è®¾ç½®ä¸º tavilyï¼Œå°è¯• Tavily
    if provider == "tavily" or (provider == "duckduckgo" and len(results) == 0):
        try:
            tavily_key = os.getenv("TAVILY_API_KEY")
            if tavily_key and tavily_key != "tvly-your-api-key":
                from tavily import TavilyClient
                
                client = TavilyClient(api_key=tavily_key)
                response = client.search(
                    query=f"Zino's Petrel {question}",
                    max_results=2,
                    search_depth="basic"
                )
                
                if response and 'results' in response:
                    results = response['results'][:2]
                    
                    if language == "Portuguese":
                        summary = "ğŸŒ **InformaÃ§Ã£o da Internet:**\n\n"
                    else:
                        summary = "ğŸŒ **Internet Information:**\n\n"
                    
                    for i, result in enumerate(results, 1):
                        title = result.get('title', 'Unknown')
                        content = result.get('content', '')[:150]
                        url = result.get('url', '')
                        
                        summary += f"{i}. **{title}**\n   {content}...\n   ğŸ”— {url}\n\n"
                    
                    return summary.strip()
        
        except ImportError:
            print("[Fact-Check] Tavily æœªå®‰è£…ï¼Œè¿è¡Œ: pip install tavily-python")
        except Exception as e:
            print(f"[Fact-Check] Tavily æœç´¢å¤±è´¥: {str(e)}")
    
    return None


def generate_fact_check_content(question, retrieved_docs, ai_answer, language="English"):
    """
    ç”Ÿæˆå®Œæ•´çš„ Fact-Check å†…å®¹ï¼ˆæ™ºèƒ½ä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£
        ai_answer: AI å›ç­”
        language: è¯­è¨€
    
    Returns:
        str: HTML æ ¼å¼çš„ Fact-Check å†…å®¹
    """
    # 1. ç”ŸæˆçŸ¥è¯†åº“æ‘˜è¦
    kb_summary = summarize_fact_check(question, retrieved_docs, ai_answer, language)
    
    # 2. å¯é€‰ï¼šæ™ºèƒ½ç½‘ç»œæœç´¢è¡¥å……ï¼ˆä¼ é€’ RAG æ–‡æ¡£ç”¨äºä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼‰
    web_summary = web_search_supplement(
        question=question, 
        retrieved_docs=retrieved_docs,  # ä¼ é€’ RAG ä¸Šä¸‹æ–‡ä¼˜åŒ–æœç´¢
        language=language
    )
    
    # 3. ç»„åˆå†…å®¹
    if language == "Portuguese":
        header = "ğŸ“‹ **VerificaÃ§Ã£o de Factos Baseada em Conhecimento CientÃ­fico**\n\n"
    else:
        header = "ğŸ“‹ **Fact-Check Based on Scientific Knowledge**\n\n"
    
    content = header + kb_summary
    
    if web_summary:
        content += f"\n\n---\n\n{web_summary}"
    
    return content

